{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose: \n",
    "This Notebook is designed as an attempt to implement the Gollini 2014 method of extracting latent positions from (multiple) network view(s).\n",
    "\n",
    "The method implements a EM - algorithm in combination with a Variational methods approach to estimation. \n",
    "\n",
    "The impact of this is twofold: \n",
    "\n",
    "Firstly, The speed gain should be significant in comparison to alternative (bayesian) methods. \n",
    "\n",
    "Secondly, The extraction of latent positions should be beneficial in relation to controlling for selection effects. \n",
    "\n",
    "\n",
    "## The algorithm: \n",
    "\n",
    "The algorithm consist of two steps: The E and the M step. Overall they are both optimization steps in the variational methods framework.\n",
    "\n",
    "#### E - Step:  estimate z_i and Sigma_i \n",
    "\n",
    "#### M - Step: Estimate alpha_M_i  and alpha_V_i^2\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Step designs a function that can estimate z_i in the single use case Next we will attempt a vectorized approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm, det\n",
    "from numpy.random import multivariate_normal\n",
    "import numpy as np\n",
    "from numpy.random import uniform, normal\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "import timeit\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Simulate companion matrix: \n",
    "\n",
    "\n",
    "def Companion_matrix(Z, alpha_0, alpha_1, N, threshold):\n",
    "    \n",
    "    dist_c = squareform(pdist(Z))\n",
    "    \n",
    "    dist_c = dist_c*dist_c\n",
    "\n",
    "    # latent utility nxn matrix:\n",
    "\n",
    "    alpha_0_nxn = np.ones((N,N))*alpha_0\n",
    "\n",
    "    alpha_1_nxn = dist_c*alpha_1\n",
    "\n",
    "    # noise term: - random gaussian noise where the upper diagonal is taken and transposed and the diagonal is divided by two\n",
    "    #E_nxn = normal(size=(N,N))\n",
    "    E_nxn = np.triu(normal(size=(N,N)))\n",
    "    E_nxn = E_nxn + E_nxn.T\n",
    "    np.fill_diagonal(E_nxn,0)\n",
    "\n",
    "    latent_utility = alpha_0_nxn + alpha_1_nxn + E_nxn\n",
    "\n",
    "    return np.where(latent_utility > threshold,1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z dim: (5000, 4)\n",
      "Y dim: (5000, 5000)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 1 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# parameters for testing: \n",
    "D=4\n",
    "N = 5000\n",
    "\n",
    "# Setting the true mean and cov-var of Z\n",
    "mean_z = np.zeros(D)\n",
    "cov_z  = np.identity(D)\n",
    "alpha_0 = 0\n",
    "alpha_1 = -0.3\n",
    "\n",
    "# generating Z:\n",
    "\n",
    "Z = multivariate_normal(mean_z, cov_z, N)\n",
    "\n",
    "# Companion matrix - This function is a bit unstable and needs to be better constructed - it will do the trick though\n",
    "\n",
    "Y = Companion_matrix(Z,  alpha_0, alpha_1, N,  0)\n",
    "\n",
    "print(\"Z dim:\", np.shape(Z))\n",
    "print(\"Y dim:\", np.shape(Y))\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-38.90402483, -16.02000226,  22.05283843, -10.82787057])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prior VARIANCE\n",
    "alpha_v_prior = 1\n",
    "alpha_m_prior = 0\n",
    "\n",
    "\n",
    "# this function should produce a gradient of size D*1:\n",
    "# for N = 1000 this precedure takes roughly 3 seconds: If this proves to be too slow one can consider working with tensors\n",
    "def zi_Gradient(i, D, sigma_est, Z_1, alpha_m, alpha_v):\n",
    "    \n",
    "    from numpy.linalg import inv as inv\n",
    "    \n",
    "    #error handling\n",
    "    if D != np.shape(sigma_est)[0]:\n",
    "        raise ValueError(\"dimension of sigma_est is not equal to dimensionality D\")\n",
    "\n",
    "    # (I + 4sigma)^-1 DxD matrix\n",
    "    alpha=np.identity(D) +  4*sigma_est\n",
    "    alpha_inv = inv(alpha)\n",
    "    \n",
    "    # Z_ij = (zi - zj) (N-1)xD matrix (i excluded)\n",
    "    z_i= Z_1[i,:]\n",
    "    Z_j = np.delete(Z_1, (i), axis=0)\n",
    "    Z_ij = z_i - Z_j\n",
    "    \n",
    "    \n",
    "    # c *exp(z_ij*alpha_inv*z_ij^T) = c*exp(quadform)\n",
    "    \n",
    "    c = np.sqrt(det(alpha))/np.exp(alpha_m + 0.5*alpha_v)\n",
    "        \n",
    "    def quadform(Z_ij, alpha_inv):\n",
    "        ZalphaZT = np.zeros(np.shape(Z_ij)[0])\n",
    "        for j in range(np.shape(Z_ij)[0]):\n",
    "             ZalphaZT[j]= Z_ij[j,:].dot(alpha_inv).dot(Z_ij[j,:].T)\n",
    "        return ZalphaZT\n",
    "        \n",
    "    \n",
    "    exp_quadform = np.exp(quadform(Z_ij, alpha_inv))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # beta = [1 + c*exp(quadform)^-1] (N-1)*1 matrix\n",
    "    \n",
    "    beta = 1/(1 + c*exp_quadform)\n",
    "    \n",
    "    # Sum_j (z_i - z_j)*beta (N-1)*D matrix\n",
    "        \n",
    "    Sum_j = (Z_ij.T * beta).T\n",
    "    \n",
    "    # Next we want to get alpha_inv * sum over N dimension to get a D*1\n",
    "    \n",
    "    sum_j = np.sum(Sum_j,axis=0)\n",
    "    \n",
    "    # returns the gradient\n",
    "    \n",
    "    return -2*alpha_inv.dot(sum_j)\n",
    "\n",
    "zi_Gradient(1, D, cov_z, Z, alpha_m_prior, alpha_v_prior)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 4)\n",
      "(5000, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "# This function should produce a Hessian of size DxD\n",
    "# -2*alpha_inv*sum_j(1 + c*exp(quadform))^-1 * [I - Z_ij Z_ij^T*alpha_inv/[1+ c*exp(quadform)]]\n",
    "def zi_Hessian(i, D, sigma_est, Z_1, alpha_m, alpha_v):\n",
    "    from numpy.linalg import inv as inv\n",
    "    # The Hessian is composed of alpha*beta*gamma (DxD * 1x1 * DxD)\n",
    "    \n",
    "    # alpha - part: DxD matrix\n",
    "    # (I + 4sigma)^-1 DxD matrix\n",
    "    alpha=np.identity(D) +  4*sigma_est\n",
    "    alpha_inv = inv(alpha)\n",
    "    \n",
    "    # beta  - part: (N-1)x1\n",
    "    # Z_ij = (zi - zj) (N-1)xD matrix (i excluded)\n",
    "    z_i= Z_1[i,:]\n",
    "    Z_j = np.delete(Z_1, (i), axis=0)\n",
    "    Z_ij = z_i - Z_j\n",
    "    \n",
    "    \n",
    "    # c *exp(z_ij*alpha_inv*z_ij^T) = c*exp(quadform)\n",
    "    \n",
    "    c = np.sqrt(det(alpha))/np.exp(alpha_m + 0.5*alpha_v)\n",
    "        \n",
    "    def quadform(Z_ij, alpha_inv):\n",
    "        ZalphaZT = np.zeros(np.shape(Z_ij)[0])\n",
    "        for j in range(np.shape(Z_ij)[0]):\n",
    "             ZalphaZT[j]= Z_ij[j,:].dot(alpha_inv).dot(Z_ij[j,:].T)\n",
    "        return ZalphaZT\n",
    "        \n",
    "    \n",
    "    exp_quadform = np.exp(quadform(Z_ij, alpha_inv))\n",
    "    \n",
    "    # the beta part (N-1)*1\n",
    "    beta = 1/(1 + c*exp_quadform)\n",
    "    \n",
    "    #now we broadcast beta into a (N-1)xDxD matrix where DxD consist of ones*beta[i]\n",
    "    N = np.shape(beta)[0]\n",
    "    def broadc_NDD(beta,D):\n",
    "        # This function broadcasts from a (N-1)x1 --> (N-1)xDxD (where DxD(i) = Ones*beta[i])\n",
    "        return np.reshape(np.repeat([np.repeat(beta,D)],D, axis=0).T,(N,D,D))\n",
    "    \n",
    "    beta_NDD = broadc_NDD(beta,D)\n",
    "    \n",
    "    # gamma = = 1/num*denom = 1/num * Z_ijZ_ij.T * alpha_inv (1x1)\n",
    "    \n",
    "    # Z_ij * Z_ij.T = Dx1 1xD = DxD \n",
    "    \n",
    "    Zij=np.reshape(Z_ij,(shape(Z_ij)[0],D,1))\n",
    "    ZijT=np.reshape(Z_ij,(shape(Z_ij)[0],1,D))\n",
    "    \n",
    "    denom = 2*(Zij * ZijT).dot(alpha_inv)\n",
    "    num = np.reshape(1 + 1/c * 1/exp_quadform,(np.shape(Z_ij)[0],1,1))\n",
    "    identity = np.identity(D)\n",
    "    \n",
    "    gamma_NDD = identity - denom * num\n",
    "    \n",
    "    #Hessian = -2 alpha_inv * sum(gamma_NDD * beta_NDD)\n",
    "    \n",
    "    Hessian =-2*alpha_inv.dot(np.sum(gamma_NDD * beta_NDD, axis = 0))\n",
    "    \n",
    "    return Hessian\n",
    "    \n",
    "\n",
    "def zi_Gradient_Hessian(N ,D, sigma_est, Z_1, alpha_m, alpha_v):\n",
    "    Gradient = np.zeros((N,D))\n",
    "    Hessian = np.zeros((N,D,D))\n",
    "    for i in range(N):\n",
    "        Gradient[i,:]=zi_Gradient(i, D, sigma_est, Z_1, alpha_m, alpha_v)\n",
    "        Hessian[i,:,:] = zi_Hessian(i, D, sigma_est, Z_1, alpha_m, alpha_v)\n",
    "    \n",
    "    #Gradient = np.reshape(Gradient,(N,D,1))\n",
    "    \n",
    "    return (Gradient, Hessian)\n",
    "        \n",
    "Gradient, Hessian = zi_Gradient_Hessian(N, D, cov_z, Z, alpha_m_prior, alpha_v_prior)\n",
    "\n",
    "print(shape(Gradient))\n",
    "print(shape(Hessian))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "## This section attempts to build a fully vectorized update step for zi:\n",
    "\n",
    "def Z_update(Y, D, Z_1, sigma_est, alpha_m, alpha_v, ):\n",
    "    \n",
    "    \n",
    "    # Defensive programming:\n",
    "    \n",
    "    if np.diag(Y).any() != 0: \n",
    "        raise ValueError(\"The diagonal of Y is non-Zero\")\n",
    "\n",
    "    # Vectorized sum over \n",
    "    sum_Y = np.reshape(np.repeat(Y.T + Y, D),(shape(Y)[0],shape(Y)[0],D))\n",
    "    sum_YZ = sum_Y * Z_1\n",
    "    \n",
    "    # summing over j\n",
    "    \n",
    "    sum_Yj = np.sum(sum_Y, axis=1)\n",
    "    sum_Yj = np.reshape(sum_Yj[:,0],(shape(sum_Y)[0],1,1))   #Nx1x1\n",
    "    sum_YZj = np.sum(sum_YZ, axis=1)\n",
    "    \n",
    "    # Denominator\n",
    "    \n",
    "    \n",
    "    #print(shape(sum_YZj))\n",
    "    #print(shape(Gradient))\n",
    "    #print(shape(Hessian))\n",
    "    #print(shape(Z_1))\n",
    "    \n",
    "    #printHessian.dot(np.reshape(Z_1,(5,4,1))))\n",
    "    \n",
    "    Z_1_ND1 = np.reshape(Z_1,(shape(Z_1)[0],D,1))\n",
    "    \n",
    "    \n",
    "    denom = sum_YZj - Gradient + np.squeeze(np.matmul(Hessian,Z_1_ND1))\n",
    "    # numerator\n",
    "    \n",
    "    I  = np.zeros((shape(sum_Y)[0],D,D)) + np.eye(D)\n",
    "\n",
    "    num =1/(2*alpha_v) + I*sum_Yj + Hessian\n",
    "    \n",
    "    \n",
    "    \n",
    "    # VERY UNSURE IF THIS PROVIDES THE CORRECT SOLUTION\n",
    "    # ax = b <=> x = a^-1*b\n",
    "    z_i = np.linalg.solve(num,np.reshape(denom,(shape(Y)[0],D,1)))\n",
    "\n",
    "    return z_i\n",
    "\n",
    "print(shape(Z_update(Y, D, Z, cov_z, alpha_m_prior, alpha_v_prior)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0\n",
      " 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def zi_update(i, Y, Z_1, D, sigma_est, alpha_m, alpha_v):\n",
    "    denom_Y = np.delete(Y[i,:] + Y[:,i],i,0)\n",
    "    denom_Y = np.delete(denom_Y,i,0)\n",
    "    print(denom_Y)\n",
    "    sum_denom = 1\n",
    "    nom = 1 pr\n",
    "    \n",
    "zi_update(1, Y, Z, D, cov_z, alpha_m_prior, alpha_v_prior)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-277-fb6c132071f3>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-277-fb6c132071f3>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    print(np.delete(a,,0))\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "print(np.delete(a,,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## from numpy import shape\n",
    "N=3\n",
    "D=2\n",
    "\n",
    "a = np.array([[[1,2],[3,4]],[[1,2],[3,4]],[[1,2],[3,4]]])\n",
    "b = np.array([1,2,3])\n",
    "\n",
    "test = np.repeat(b,2)\n",
    "test = np.repeat([test],2, axis=0)\n",
    "test2 = np.reshape(test.T,(3,2,2))\n",
    "print(shape(test2))\n",
    "print(test2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a - test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3], [4,6,7]])\n",
    "b= np.reshape(a,(2,1,3))\n",
    "c = np.reshape(a.T,(2,1,3))\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  6]\n",
      " [ 8 18]]\n",
      "[[10 15]\n",
      " [16 24]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2],[2,3]])\n",
    "b = np.array([[2,3],[4,6]])\n",
    "print(a*b)\n",
    "print(a.dot(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.ones((2, 3))\n",
    "a = np.arange(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 1.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 1.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 1.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 1.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 1.]]]\n",
      "(5, 3, 3)\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "(3, 1)\n",
      "[[[1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]]]\n",
      "(5, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((5,3,3)) + np.eye(3)\n",
    "print(a)\n",
    "print(shape(a))\n",
    "\n",
    "b =np.reshape(np.ones(3),(3,1))\n",
    "print(b)\n",
    "print(shape(b))\n",
    "\n",
    "c = np.matmul(a,b)\n",
    "print(c)\n",
    "print(shape(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
